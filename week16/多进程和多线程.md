# 多进程和多线程

### 1 基础知识

现代操作系统比如Mac OS X，UNIX，Linux，Windows等，都是支持“多任务”的操作系统。 什么叫“多任务”呢？简单地说，就是操作系统可以==同时运行多个任务==。打个比方，你==一边在用浏览器上网，一边在听MP3，一边在用Word赶作业==，这就是多任务，==至少同时有3个任务正在运行==。还有很多任务悄悄地在后台同时运行着，只是桌面上没有显示而已。

现在，多核CPU已经非常普及了，但是，即使过去的单核CPU，也可以执行多任务。由于CPU执行代码都是顺序执行的，那么，==单核CPU是怎么执行多任务==的呢？

答案就是==操作系统轮流让各个任务交替执行==，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，我们==感觉就像所有任务都在同时执行一样==。

==真正的并行执行==多任务只能在多核CPU上实现，但是，由于==任务数量远远多于CPU的核心数量==，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行。

对于操作系统来说，==一个任务就是一个进程（Process）==，==比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个Word就启动了一个Word进程。==

有些进程还不止同时干一件事，比如Word，它可以同时进行打字、拼写检查、打印等事情。==在一个进程内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”称为线程（Thread）==。

==由于每个进程至少要干一件事，所以，一个进程至少有一个线程==。当然，像Word这种==复杂的进程可以有多个线程==，多个线程可以“同时”执行，==多线程的执行方式和多进程是一样的，也是由操作系统在多个线程之间快速切换==，让每个线程都短暂地交替运行，看起来就像同时执行一样。当然，真正地同时执行多线程需要多核CPU才可能实现。

我们前面编写的所有的Python程序，都是执行单任务的进程，也就是只有一个线程。如果我们要==同时执行多个任务==怎么办？

有两种解决方案：

一种是==启动多个进程，每个进程虽然只有一个线程==，但多个进程可以一块执行多个任务。

还有一种方法是==启动一个进程==，在==一个进程内启动多个线程==，这样，多个线程也可以一块执行多个任务。

当然还有第三种方法，就是==启动多个进程，每个进程再启动多个线程==，这样同时执行的任务就更多了，当然这种模型更复杂，==实际很少采用==。

总结一下就是，多任务的实现有3种方式：

- 多进程模式；
- 多线程模式；
- 多进程+多线程模式。

同时执行多个任务==通常各个任务之间并不是没有关联的==，而是==需要相互通信和协调==，有时，任务1必须暂停等待任务2完成后才能继续执行，有时，任务3和任务4又不能同时执行，所以，多进程和多线程的程序的复杂度要远远高于我们前面写的单进程单线程的程序。

因为复杂度高，调试困难，所以，不是迫不得已，我们也不想编写多任务。但是，有很多时候，没有多任务还真不行。想想==在电脑上看电影==，就必须由一个线程播放视频，另一个线程播放音频，否则，单线程实现的话就只能先把视频播放完再播放音频，或者先把音频播放完再播放视频，这显然是不行的。

#### 总结

线程是最小的执行单元，而==进程由至少一个线程组成==。如何调度进程和线程，完全由==操作系统决定==，程序自己不能决定什么时候执行，执行多长时间。 

每一个进程启动时都会最先产生一个线程，即==主线程==。然后主线程会再创建其他的==子线程==。

### 2 Python 多线程

#### 2.1 GIL

其他语言，CPU 是多核时是支持多个线程同时执行。但==在 Python 中，无论是单核还是多核，同时只能由一个线程在执行==。其根源是 ==CPython中GIL 的存在==。

GIL 的全称是 ==Global Interpreter Lock(全局解释器锁)==，来源是 Python 设计之初的考虑，为了==数据安全==所做的决定。某个线程想要执行，必须先拿到 GIL，我们可以把 GIL 看作是“通行证”，并且==在一个 Python 进程中，GIL 只有一个。拿不到通行证的线程，就不允许进入 CPU 执行==。

每次释放 GIL锁，线程进行==锁竞争、切换线程，会消耗资源==。这就导致打印线程执行时长，会发现耗时更长的原因。

并且由于 GIL 锁存在，==Python 里一个进程永远只能同时执行一个线程==(拿到 GIL 的线程才能执行)，这就是为什么在多核CPU上，Python 的多线程效率并不高的根本原因。

#### 2.2 创建多线程

Python提供两个模块进行多线程的操作，分别是thread和threading，
 前者是比较低级的模块，用于更底层的操作，==一般应用级别的开发不常用==。

- 方法1：直接使用threading.Thread() 

```python
import threading

# 这个函数名可随便定义
def run(n):
    print("current task：", n)

if __name__ == "__main__":
    t1 = threading.Thread(target=run, args=("thread 1",))
    t2 = threading.Thread(target=run, args=("thread 2",))
    t1.start()
    t2.start()
```

- 方法2：继承threading.Thread来自定义线程类，重写run方法

```python
import threading

class MyThread(threading.Thread):
    def __init__(self, n):
        super(MyThread, self).__init__()  # 重构run函数必须要写
        self.n = n
	# 必须实现run方法
    def run(self):
        print("current task：", n)

if __name__ == "__main__":
    t1 = MyThread("thread 1")
    t2 = MyThread("thread 2")

    t1.start()
    t2.start()
```

#### 2.3 线程合并

Join函数执行顺序是逐个执行每个线程，执行完毕后继续往下执行。==主线程结束后==，子线程还在运行，join函数==使得主线程等到子线程结束时才退出==。

```python
import threading

def count(n):
    while n > 0:
        n -= 1

if __name__ == "__main__":
    t1 = threading.Thread(target=count, args=("100000",))
    t2 = threading.Thread(target=count, args=("100000",))
    t1.start()
    t2.start()
    # 将 t1 和 t2 加入到主线程中
    t1.join()
    t2.join()
```

知识点一：
当一个进程启动之后，会默认产生一个==主线程==，因为线程是程序执行流的最小单元，当设置多线程时，主线程会创建多个子线程，在python中，默认情况下（其实就是==setDaemon(False)==），==主线程执行完自己的任务以后，就退出了==，此时子线程会继续执行自己的任务，直到自己的任务结束，例子见下面一。

知识点二：
当我们使用setDaemon(True)方法，设置==子线程==为守护线程时，==主线程一旦执行结束，则全部线程全部被终止执行==，可能出现的情况就是，==子线程的任务还没有完全执行结束，就被迫停止==，例子见下面二。

知识点三：
此时join的作用就凸显出来了，join所完成的工作就是==线程同步==，即==主线程任务结束之后，进入阻塞状态，一直等待其他的子线程执行结束之后，主线程再终止==，例子见下面三。

知识点四：
==join有一个timeout参数==：==当设置守护线程时==，含义是主线程对于子线程==等待timeout的时间将会杀死该子线程，最后退出程序==。所以说，如果有10个子线程，全部的等待时间就是==每个timeout的累加和==。简单的来说，就是==给每个子线程一个timeout的时间，让他去执行，时间一到，不管任务有没有完成，直接杀死。==
没有设置守护线程时，主线程将会等待timeout的累加和这样的一段时间，时间一到，==主线程结束，但是并没有杀死子线程，子线程依然可以继续执行==，直到子线程全部结束，程序退出。

**一：Python多线程的默认情况**

```
import threading
import time

def run():
    time.sleep(2)
    print('当前线程的名字是： ', threading.current_thread().name)
    time.sleep(2)


if __name__ == '__main__':

    start_time = time.time()

    print('这是主线程：', threading.current_thread().name)
    thread_list = []
    for i in range(5):
        t = threading.Thread(target=run)
        thread_list.append(t)

    for t in thread_list:
        t.start()

    print('主线程结束！' , threading.current_thread().name)
    print('一共用时：', time.time()-start_time)
```

其执行结果如下
![这里写图片描述](https://img-blog.csdn.net/2018041413191819?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppZWRlMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

关键点：

我们的计时是对==主线程==计时，==主线程结束，计时随之结束==，打印出主线程的用时。
主线程的任务完成之后，主线程随之结束，子线程继续执行自己的任务，直到全部的子线程的任务全部结束，程序结束。
**二：设置守护线程**

```
import threading
import time

def run():

    time.sleep(2)
    print('当前线程的名字是： ', threading.current_thread().name)
    time.sleep(2)


if __name__ == '__main__':

    start_time = time.time()

    print('这是主线程：', threading.current_thread().name)
    thread_list = []
    for i in range(5):
        t = threading.Thread(target=run)
        thread_list.append(t)

    for t in thread_list:
        t.setDaemon(True)
        t.start()

    print('主线程结束了！' , threading.current_thread().name)
    print('一共用时：', time.time()-start_time)
```

其执行结果如下，注意==请确保setDaemon()在start()之前==。

![这里写图片描述](https://img-blog.csdn.net/20180414132025269?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppZWRlMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

关键点：

非常明显的看到，主线程结束以后，子线程==还没有来得及执行==，整个程序就退出了。
**三：join的作用**

```
import threading
import time

def run():

    time.sleep(2)
    print('当前线程的名字是： ', threading.current_thread().name)
    time.sleep(2)


if __name__ == '__main__':

    start_time = time.time()

    print('这是主线程：', threading.current_thread().name)
    thread_list = []
    for i in range(5):
        t = threading.Thread(target=run)
        thread_list.append(t)

    for t in thread_list:
        t.setDaemon(True)
        t.start()

    for t in thread_list:
        t.join()

    print('主线程结束了！' , threading.current_thread().name)
    print('一共用时：', time.time()-start_time)
```

其执行结果如下：
![这里写图片描述](https://img-blog.csdn.net/20180414132116262?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppZWRlMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

#### 2.4 线程同步与互斥锁

==线程之间数据共享==的。当多个线程对某一个共享数据进行操作时，就需要考虑到==线程安全问题==。threading模块中定义了Lock 类，提供了互斥锁的功能来保证多线程情况下数据的正确性。

==用法的基本步骤：==

```python
#创建锁
mutex = threading.Lock()
#锁定
mutex.acquire([timeout])
#释放
mutex.release()
```

其中，锁定方法acquire可以有一个==超时时间的可选参数timeout==。如果设定了timeout，则在==超时后通过返回值可以判断是否得到了锁==，从而可以进行一些其他的处理。 

获得锁的线程用完后==一定要释放锁==，否则那些苦苦等待锁的线程将永远等待下去，成为==死线程==。所以我们用`try...finally`来确保锁一定会被释放。 

具体用法见示例代码：

```python
import threading
import time

num = 0
mutex = threading.Lock()

class MyThread(threading.Thread):
    def run(self):
        global num 
        time.sleep(1)

        if mutex.acquire(1):  
            num = num + 1
            msg = self.name + ': num value is ' + str(num)
            print(msg)
            mutex.release()

if __name__ == '__main__':
    for i in range(5):
        t = MyThread()
        t.start()
```

#### 2.5 可重入锁（递归锁）

为了满足在==同一线程中多次请求同一资源的需求==，Python 提供了可重入锁（RLock）。
RLock内部维护着一个Lock和一个counter变量，==counter 记录了 acquire 的次数，从而使得资源可以被多次 require。直到一个线程所有的 acquire 都被 release，其他的线程才能获得资源==。

具体用法如下：

```python
#创建 RLock
mutex = threading.RLock()

class MyThread(threading.Thread):
    def run(self):
        if mutex.acquire(1):
            print("thread " + self.name + " get mutex")
            time.sleep(1)
            mutex.acquire()
            mutex.release()
            mutex.release()
```

#### 2.6 守护线程

==如果希望主线程执行完毕之后，不管子线程是否执行完毕都随着主线程一起结束。==我们可以使用setDaemon(bool)函数，它跟join函数是相反的。它的作用是设置子线程是否随主线程一起结束，必须在start() 之前调用，默认为False。

#### 2.7 定时器

如果需要规定函数==在多少秒后执行某个操作==，需要用到Timer类。具体用法如下：

```python
from threading import Timer
 
def show():
    print("Pyhton")

# 指定一秒钟之后执行 show 函数
t = Timer(1, hello)
t.start()  
```

#### 2.8 线程的名字

 Python的threading模块有个==current_thread()函数==，它==永远返回当前线程的实例==。主线程实例的名字叫==MainThread==，==子线程的名字在创建时指定==。名字==仅仅在打印时用来显示，完全没有其他意义==，如果不起名字Python就==自动给线程命名为Thread-1，Thread-2==…… 

#### 2.9 油条的故事- Event实现

需求：一个冬天的早晨，顾客去小摊贩那里买油条，由于油条都是现炸，所以顾客需要等待小摊贩生产油条，小摊贩生产好油条后顾客可以进餐，结束后打招呼离开

分析：这里有两个线程，小摊贩线程和顾客线程，顾客线程运行开始必须等待，小摊贩线程工作生产油条，==当油条生产之后唤醒顾客线程==，==此时小摊贩线程等待，顾客就餐完毕之后准备离开==，==唤醒小摊贩结账走人==！

```
set()添加标记
isSet()/is_set()检查事件对象是否被标记
wait()线程等待-如果当前事件对象被标记~继续运行
clear()清除标记
```

```ruby
import threading
import time

# 定义事件对象
event = threading.Event()


def xiao_fan():
    print("XF,炸油条.......")
    time.sleep(2)
    # 添加标记
    event.set()
    event.clear()

    print("XF, 卖油条")

    event.wait()
    print("XF:结账完毕，谢谢光临")


def gu_ke():
    # 线程等待~等待事件对象被标记
    event.wait()
    print("GK:买油条")
    print("GK:吃油条")
    time.sleep(2)


if __name__ == "__main__":
    xf = threading.Thread(target=xiao_fan)
    gk = threading.Thread(target=gu_ke)

    xf.start()
    gk.start()

```

#### 2.10 线程管理-条件Condition

线程条件Condition对象，也是多线程并发模式下一种线程之间通信的友好支持。在某些情况下，我们需要多个线程在运行过程中根据实际操作情况，不同功能的线程在==满足对应的条件时等待、启动两种状态之间进行切换==

如经典的线程间通信问题：生产者消费者问题。生产者负责上生产食物，将食物存储在列表中；消费者负责消费，也就是从列表中删除数据；这里的存储食物的列表，我们限制了长度，最多容纳20个食物数据。此时就会出现这样的问题，如果列表中的食物已经达到20；那么所有的生产者线程不能继续生产食物了，必须处于等待状态，==等待消费者消费了食物之后再次生产==。同理如果列表中的食物为空了，所有的消费者也就不能吃食物了，必须处于等待状态，等待生产者生产了食物之后才能消费

```bash
Conditon（）对象的属性和方法
acquire()锁定
release()解锁
wait()释放锁，同时阻塞当前线程，等待被唤醒
wait_for()释放锁，同时阻塞当前线程，等待被唤醒
notify()唤醒
notify_all()唤醒所有等待condition条件的线程
```

#### 2.11 生产者消费者问题-Condition 实现

需求：生产者消费者问题，描述的是多个线程之间的通信处理方式和手段。多个生产者线程生产食品放到指定的食品容器中，并唤醒所有的消费者线程开始就餐。==如果食品容器容量饱和，则所有生产者线程等待==。多个消费者线程在指定的视屏容器中获取食物就餐，并唤醒所有的生产者线程开始生产，如果食品容器中没有任何食品了，则所有消费者线程等待。

```php
import random
import threading
import time

# 定义食物列表
foods = list()
# 创建一个线程条件对象
con = threading.Condition()


def product():
    while True:
        time.sleep(0.5)
        con.acquire()
        if len(foods) < 20:
            _no = random.randint(0, 20)
            print("生产者{}生产了{}".format(threading.current_thread().getName(), _no))
            foods.append(_no)
            print("PRO--", len(foods))
            con.notify()
        else:
            con.wait()
            print("生产者{}----等待".format(threading.current_thread().getName()))
            con.release()


def consumer():
    while True:
        time.sleep(0.5)
        con.acquire()
        if len(foods) > 0:
            _no = foods.pop()
            print("消费者{}消费了".format(threading.current_thread().getName()), _no)
            print("CUS--", len(foods))
            con.notify()
        else:
            con.wait()
            print("消费者{}-----等待".format(threading.current_thread().getName()))
            con.release()


if __name__ == "__main__":
    # 创建多个生产者线程
    for i in range(5):
        p = threading.Thread(name="_p" + str(i), target=product)
        p.start()
    # 创建多个消费者线程
    for j in range(2):
        c = threading.Thread(name="_c" + str(j), target=consumer)
        c.start()
```

### 3 Python 多进程

#### 3.1 创建多进程

Python 要进行多进程操作，需要用到muiltprocessing库，其中的Process类跟threading模块的Thread类很相似。所以直接看代码熟悉多进程。

- 方法1：直接使用Process, 代码如下：

```python
from multiprocessing import Process  

def show(name):
    print("Process name is " + name)

if __name__ == "__main__": 
    proc = Process(target=show, args=('subprocess',))  
    proc.start()  
    proc.join()
```

- 方法2：继承Process来自定义进程类，重写run方法, 代码如下：

```python
from multiprocessing import Process
import time

class MyProcess(Process):
    def __init__(self, name):
        super(MyProcess, self).__init__()
        self.name = name

    def run(self):
        print('process name :' + str(self.name))
        time.sleep(1)

if __name__ == '__main__':
    for i in range(3):
        p = MyProcess(i)
        p.start()
    for i in range(3):
        p.join()
```

#### 3.2 多进程通信

进程之间不共享数据的。如果==进程之间需要进行通信==，则要用到Queue模块或者Pipi模块来实现。

- **Queue**

Queue 是==多进程安全==的队列，可以实现==多进程之间的数据传递==。它主要有两个函数,put和get。

put() 用以插入数据到队列中，put 还有两个可选参数：==blocked 和 timeout==。==如果 blocked 为 True（默认值），并且 timeout 为正值==，该方法会阻塞 timeout 指定的时间，直到该队列有剩余的空间。如果超时，会抛出 ==Queue.Full== 异常。如果 blocked 为 False，但该 Queue 已满，会==立即抛出== Queue.Full 异常。

get()可以从队列读取并且删除一个元素。同样，get 有两个可选参数：==blocked 和 timeout==。如果 blocked 为 True（默认值），并且 timeout 为正值，那么在等待时间内没有取到任何元素，会抛出 Queue.Empty 异常。如果blocked 为 False，有两种情况存在，如果 Queue 有一个值可用，则立即返回该值，否则，如果队列为空，则立即抛出 Queue.Empty 异常。

具体用法如下：

```python
from multiprocessing import Process, Queue
 
def put(queue):
    queue.put('Queue 用法')
 
if __name__ == '__main__':
    queue = Queue()
    pro = Process(target=put, args=(queue,))
    pro.start()
    print(queue.get())   
    pro.join()
```

- **Pipe**

Pipe的本质是进程之间的==用管道数据传递，而不是数据共享==，这和socket有点像。pipe() 返回两个连接对象分别表示管道的两端，==每端都有send() 和recv()函数==，默认情况下是==双工（双向）==。如果duplex是False，那么管道是单向的：==conn1只能用于接收消息，conn2只能用于发送消息==。

如果两个进程试图在==同一时间的同一端进行读取和写入==那么，这可能会损坏管道中的数据。

具体用法如下：

```python
from multiprocessing import Process, Pipe
 
def show(conn):
    conn.send('Pipe 用法')
    conn.close()
 
if __name__ == '__main__':
    parent_conn, child_conn = Pipe() 
    pro = Process(target=show, args=(child_conn,))
    pro.start()
    print(parent_conn.recv())   
    pro.join()
```

#### 3.3 进程池

创建多个进程，我们不用傻傻地一个个去创建。我们可以使用Pool模块来搞定。  可以通过传递参数限制并发进程的数量， 默认值为CPU的核数 

Pool类可以==提供指定数量的进程==供用户调用，当有新的请求提交到Pool中时，如果==进程池还没有满，就会创建一个新的进程来执行请求==。如果池满，请求就会告知先等待，直到池中有进程结束，才会创建新的进程来执行这些请求。

下面介绍一下multiprocessing 模块下的Pool类的几个方法：

1.apply_async

函数原型：apply_async(func[, args=()[, kwds={}[, callback=None]]])

其作用是向进程池==提交需要执行的函数及参数==， 各个进程采用非阻塞（异步）的调用方式，==即每个子进程只管运行自己的，不管其它进程是否已经完成。这是默认方式。==

2.map()

函数原型：map(func, iterable[, chunksize=None])

Pool类中的map方法，==与内置的map函数用法行为基本一致==，它会使进程阻塞直到结果返回。 注意：虽然第二个参数是一个迭代器，但在实际使用中，必须在整个队列都就绪后，程序才会运行子进程。

3.map_async()

函数原型：map_async(func, iterable[, chunksize[, callback]])
与map用法一致，但是它是非阻塞的。其有关事项见apply_async。

4.close()

关闭进程池（pool），使其不在接受新的任务。

5.terminate()

结束工作进程，不在处理未处理的任务。

6.join()

主进程阻塞等待子进程的退出， join方法==要在close或terminate之后使用==。

具体用法见示例代码：

```python
from multiprocessing import Pool
def show(num):
    print('num : ' + str(num))

if __name__=="__main__":
    pool = Pool(processes = 3)
    for i in xrange(6):
        # 维持执行的进程总数为processes，当一个进程执行完毕后会添加新的进程进去
        pool.apply_async(show, args=(i, ))       
    print('======  apply_async  ======')
    pool.close()
    #调用join之前，先调用close函数，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束
    pool.join()
```

### 4.进程 vs. 线程

首先，要实现多任务，通常我们会设计==Master-Worker模式==，==Master负责分配任务，Worker负责执行任务==，因此，多任务环境下，==通常是一个Master，多个Worker==。

如果用多进程实现Master-Worker，主进程就是Master，其他进程就是Worker。

如果用多线程实现Master-Worker，主线程就是Master，其他线程就是Worker。

多进程模式最大的优点就是==稳定性高==，因为==一个子进程崩溃了，不会影响主进程和其他子进程==。（当然主进程挂了所有进程就全挂了，但是Master进程只负责分配任务，挂掉的概率低）著名的Apache最早就是采用多进程模式。

多进程模式的缺点是==创建进程的代价大==，在Unix/Linux系统下，用`fork`调用还行，在Windows下创建进程开销巨大。另外，==操作系统能同时运行的进程数也是有限的==，在内存和CPU的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。

多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是==任何一个线程挂掉都可能直接造成整个进程崩溃==，==因为所有线程共享进程的内存==。在Windows上，如果一个线程执行的代码出了问题，你经常可以看到这样的提示：“==该程序==执行了非法操作，即将关闭”，其实往往是某个线程出了问题，但是操作系统会强制结束整个进程。

在Windows下，多线程的效率比多进程要高，所以微软的IIS服务器默认采用多线程模式。由于多线程存在稳定性的问题，IIS的稳定性就不如Apache。为了缓解这个问题，IIS和Apache现在又有多进程+多线程的混合模式，真是把问题越搞越复杂。

### 5.线程切换

无论是多进程还是多线程，只要数量一多，效率肯定上不去，为什么呢？

我们打个比方，假设你不幸正在准备中考，每天晚上需要做语文、数学、英语、物理、化学这5科的作业，每项作业耗时1小时。

如果你先花1小时做语文作业，做完了，再花1小时做数学作业，这样，依次全部做完，一共花5小时，这种方式称为==单任务模型，或者批处理任务模型==。

假设你打算切换到多任务模型，可以先做1分钟语文，再切换到数学作业，做1分钟，再切换到英语，以此类推，只要切换速度足够快，这种方式就和单核CPU执行多任务是一样的了，以幼儿园小朋友的眼光来看，你就正在同时写5科作业。

但是，切换作业是有代价的，比如从语文切到数学，要先收拾桌子上的语文书本、钢笔（这叫==保存现场==），然后，打开数学课本、找出圆规直尺（这叫==准备新环境==），才能开始做数学作业。操作系统在切换进程或者线程时也是一样的，它需要==先保存当前执行的现场环境（CPU寄存器状态、内存页等），然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换内存页等）==，才能开始执行。这个切换过程虽然很快，但是也需要耗费时间。如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是==硬盘狂响，点窗口无反应，系统处于假死状态==。

所以，多任务一旦多到一个限度，就会消耗掉系统所有的资源，结果效率急剧下降，所有任务都做不好。

### 6.计算密集型 vs. IO密集型

是否采用多任务的第二个考虑是任务的类型。我们可以把任务分为计算密集型和IO密集型。

计算密集型任务的特点是要==进行大量的计算==，消耗CPU资源，比如计算圆周率、==对视频进行高清解码==等等，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，==要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数==。

计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。==对于计算密集型任务，最好用C语言编写。==

第二种任务的类型是IO密集型，涉及到==网络、磁盘IO==的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，==任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）==。对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。

IO密集型任务执行期间，==99%的时间都花在IO上==，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，完全无法提升运行效率。对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差。